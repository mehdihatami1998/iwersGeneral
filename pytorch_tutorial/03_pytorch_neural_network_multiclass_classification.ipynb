{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a multiclass data \n",
    "\n",
    "# hyperparameters\n",
    "NUM_CLASSES = 4\n",
    "NUM_FEATURES = 2\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "X_blob, y_blob = make_blobs(n_samples=1000,\n",
    "                            n_features=NUM_FEATURES,\n",
    "                            centers=NUM_CLASSES,\n",
    "                            cluster_std=1.5,\n",
    "                            random_state=RANDOM_SEED)\n",
    "\n",
    "# we know that scikit-learn works on Numpy, so will be these data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also create an accuracy function to measure how right our model is\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    accuracy = (correct / len(y_true)) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got Tensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vw/_7ms67xn1jxb_9zqbfcn4q080000gn/T/ipykernel_43731/2880730549.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# to work with pytorch we need to transform our data into tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_blob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_blob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_blob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_blob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# split our data into training and test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got Tensor)"
     ]
    }
   ],
   "source": [
    "# to work with pytorch we need to transform our data into tensors\n",
    "X_blob = torch.from_numpy(X_blob).type(torch.float)\n",
    "y_blob = torch.from_numpy(y_blob).type(torch.LongTensor) \n",
    "\n",
    "# split our data into training and test\n",
    "X_blob_train, X_blob_test, y_blob_train, y_blob_test = train_test_split(X_blob,\n",
    "                                                                        y_blob,\n",
    "                                                                        test_size=0.2,\n",
    "                                                                        random_state=RANDOM_SEED)\n",
    "\n",
    "# lets visualize our data\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(X_blob[:, 0], X_blob[:, 1], c=y_blob, cmap=plt.cm.RdYlBu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model class now\n",
    "# make it device-agnostics\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class BlobModel(nn.Module):\n",
    "    def __init__(self, input_features, output_features, hidden_units=8):\n",
    "        \"\"\" Initializes multi-class classification model.\n",
    "\n",
    "        Args:\n",
    "            input_features (int): Number of input features to the model\n",
    "            output_features (int): Number of output features (classes)\n",
    "            hidden units (int): Number of hidden units between layers (default=8)\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "\n",
    "        Examples:\n",
    "            >>> model = BlobModel(2, 4)\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.linear_layer_stack =  nn.Sequential(\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_layer_stack(x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlobModel(\n",
       "  (linear_layer_stack): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=8, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=8, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets create an instance model from the model class and send it to the device\n",
    "model_0 = BlobModel(input_features=2,\n",
    "                    output_features=4,\n",
    "                    hidden_units=8).to(device)\n",
    "\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before creating a training/evaluation loop, we should create a loss function and an optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
    "                            lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we put our model on the device, so before starting the loop, we should put our data on device as well.\n",
    "X_blob_test, y_blob_test = X_blob_test.to(device), y_blob_test.to(device)\n",
    "X_blob_train, y_blob_train = X_blob_train.to(device), y_blob_train.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 4])\n",
      "torch.Size([800])\n"
     ]
    }
   ],
   "source": [
    "print(y_logits.shape)\n",
    "print(y_blob_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, | Train Accuracy: 27.75%, | Test Accucary: 29.00%\n",
      "Epoch: 10, | Train Accuracy: 96.00%, | Test Accucary: 98.50%\n",
      "Epoch: 20, | Train Accuracy: 99.12%, | Test Accucary: 99.50%\n",
      "Epoch: 30, | Train Accuracy: 99.12%, | Test Accucary: 99.50%\n",
      "Epoch: 40, | Train Accuracy: 99.12%, | Test Accucary: 99.50%\n",
      "Epoch: 50, | Train Accuracy: 99.12%, | Test Accucary: 99.50%\n",
      "Epoch: 60, | Train Accuracy: 99.12%, | Test Accucary: 99.50%\n",
      "Epoch: 70, | Train Accuracy: 99.12%, | Test Accucary: 99.50%\n",
      "Epoch: 80, | Train Accuracy: 99.25%, | Test Accucary: 99.50%\n",
      "Epoch: 90, | Train Accuracy: 99.25%, | Test Accucary: 99.50%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed = 42\n",
    "torch.cuda.manual_seed = 42\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ## Training:\n",
    "    # Step 0: put the model on the training mode\n",
    "    model_0.train()\n",
    "\n",
    "    # Step 1: forward pass\n",
    "    y_logits = model_0(X_blob_train) # raw outputs of our model\n",
    "    y_preds = torch.softmax(y_logits, dim=1).argmax(dim=1)# prediction label\n",
    "\n",
    "    # Step 2: calculate the loss and accuracy\n",
    "    train_loss = loss_fn(y_logits, y_blob_train)\n",
    "    train_acc = accuracy_fn(y_true=y_blob_train,\n",
    "                            y_pred=y_preds)\n",
    "\n",
    "    # Step 3: zero gradiant of optimizer\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Step 4: backward propagation\n",
    "    train_loss.backward()\n",
    "\n",
    "    # Step 5:\n",
    "    optimizer.step()\n",
    "\n",
    "    ## Testing:\n",
    "    # Step 0: put the model on evaluation mode\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Step 1:\n",
    "        test_logits = model_0(X_blob_test)\n",
    "        test_preds = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "\n",
    "        # Step 2: calculate the loss and accuracy\n",
    "        test_loss = loss_fn(test_logits, y_blob_test)\n",
    "        test_acc = accuracy_fn(y_true=y_blob_test,\n",
    "                                y_pred=test_preds)\n",
    "\n",
    "\n",
    "    # Step 3: Print out what is happening\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, | Train Accuracy: {train_acc:.2f}%, | Test Accucary: {test_acc:.2f}%\")\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can find some accuracy matrix on torchmetrics library\n",
    "# from torchmetrics import Accuracy ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
